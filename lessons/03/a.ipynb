{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.9.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import Tensor, nn"
   ]
  },
  {
   "source": [
    "# Implementazione di regressore softmax\n",
    "Carichiamo dataset delle iris di fisher. Contenente\n",
    "- 4 quantità relative (features)\n",
    "- 150 fiori (classi)\n",
    "- 3 specie diverse (istanze)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "features (150, 4) \n classi target (150,) \n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X=iris.data\n",
    "Y=iris.target\n",
    "print(\"features\", X.shape,\n",
    "    \"\\n classi target\", Y.shape,\n",
    "    \"\\n\", Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inizializzazione\n",
    "\n",
    "## seed per risultati ripetibili\n",
    "np.random.seed(1234)\n",
    "torch.random.manual_seed(1234)\n",
    "\n",
    "## permutazione casuale dei dati\n",
    "idx = np.random.permutation(len(X))\n",
    "\n",
    "## applico la stessa sia a X che a Y\n",
    "X = X[idx]\n",
    "Y = Y[idx]\n",
    "\n",
    "## suddivido dataset in training e testing set indipendenti e trasformiamo gli array in tensori\n",
    "X_training = Tensor(X[30:])\n",
    "Y_training = Tensor(Y[30:])\n",
    "X_testing = Tensor(X[:30])\n",
    "Y_testing = Tensor(Y[:30])\n",
    "\n",
    "## normalizzo i dati\n",
    "X_mean = X_training.mean(0)\n",
    "X_std = X_training.std(0)\n",
    "\n",
    "X_training_norm = (X_training-X_mean)/X_std\n",
    "X_testing_norm = (X_testing-X_mean)/X_std\n"
   ]
  },
  {
   "source": [
    "Definisco un nuovo modulo per effettuare la regressione softmax "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftMaxRegressor(nn.Module):\n",
    "    def __init__(self, in_features, out_classes):\n",
    "        \"\"\"Costruisce un regressore softmax\n",
    "            Input:\n",
    "                in_features: numero di feature in input (es.4)\n",
    "                out_classes: numero di classi in uscita (es.3) \"\"\"\n",
    "        super(SoftMaxRegressor, self).__init__()    ## richiamo costruttore della superclasse, passo necessario per abilitare alcuni meccanismi automatici di PyTorch\n",
    "\n",
    "        self.linear = nn.Linear(in_features, out_classes)   ## il regressore softmax restituisce distr di probabilità, quindi il numero di feature di output coincide con il numero di classi. è lineare in quanto il softmax viene implementato nella loss\n",
    "\n",
    "    def forward(self,x):\n",
    "        \"\"\"Definisce come processare l'input x\"\"\"\n",
    "        scores = self.linear(x)\n",
    "        return scores"
   ]
  },
  {
   "source": [
    "Costruiamo un regressore softmax e passiamogli i dati di training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.9326,  0.6582, -0.2940],\n",
       "        [-0.1301, -0.2885,  0.1746],\n",
       "        [ 1.1440,  1.6170, -1.0236],\n",
       "        [-0.1766, -0.4061,  0.2196],\n",
       "        [-0.4706, -0.5166,  0.2307],\n",
       "        [ 1.2162,  1.5326, -0.9408],\n",
       "        [ 1.6219,  1.6549, -0.9210],\n",
       "        [ 0.8984,  1.2598, -0.8457],\n",
       "        [ 1.4105,  1.9569, -1.2018],\n",
       "        [ 1.0097,  0.5520, -0.2012]], grad_fn=<SliceBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "## z = torch.Tensor([14,4.3, 100])\n",
    "\n",
    "## implementazione grezza del softmax\n",
    "## def softmax(z):\n",
    "##    z = z-torch.max(z)      ## permette che sia più robusta per i numeri più grandi\n",
    "##    z_exp = torch.exp(z)\n",
    "##    return z_exp/z_exp.sum()\n",
    "\n",
    "## print(softmax(z))\n",
    "\n",
    "model = SoftMaxRegressor(4,3) # 4 feature in ingresso, 3 classi in uscita\n",
    "#mostriamo le prime 4 predizioni\n",
    "model(X_training_norm)[:10]"
   ]
  },
  {
   "source": [
    "ogni riga della matrice è una predizione. Non si tratta di valide distribuzioni di probabilità, per ottenere le distribuzioni usiamo softmax"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "#softmax(model(X_training_norm))[:10]\n",
    "\n",
    "## adesso abbiamo una valida distribuzioni di probabilità sulle tre classi. la somma lunghe le righe è pari a 1 infatti:\n",
    "\n",
    "#softmax(model(X_training_norm)).sum(1)"
   ]
  },
  {
   "source": [
    "una volta allenato, il modello permetterà di predire una distribuzione di probabilità per ogni elemento. per ottenere l'etichetta predetta, applichiamo il principio Maximum A Posteriori (MAP), scegliendo la classe che presenta la probabilità maggiore mediante argmax inclusa in pytorch nella funzione max"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.35833333333333334\n"
     ]
    }
   ],
   "source": [
    "# ritorna i valori dei massimi e i loro indici (il ris della funzione argmax)\n",
    "# per questo includiamo [1] nell'equazione successiva\n",
    "\n",
    "preds = softmax(model(X_training_norm)).max(1)[1]\n",
    "preds\n",
    "\n",
    "## dopo aver ottenuto le predizioni sotto forma di indici delle rte classi che vanno da 0 a 2 possiamo valutare le predizioni come visto nel caso binario. calcoliamo l'accuracy\n",
    "\n",
    "print(accuracy_score(Y_training, preds))"
   ]
  },
  {
   "source": [
    "L'accuracy è molto bassa in quanto dobbiamo ancora allenare il modello\n",
    "\n",
    "Dato che la funzione softmax è monotona, possiamo applicare argmax direttamente ai logits ottenendo lo stesso risultato\n",
    "\n",
    "```\n",
    "preds_logits= model(X_training_norm).max(1)[1]\n",
    "print((preds_logits==preds).float().mean()) #il risultato ottenuto è lo stesso\n",
    "```\n",
    "\n",
    "In pratica si preferisce non applicare softmax per il calcolo delle etichette predette\n",
    "(mancano le formulette)\n",
    "La procedura di training del regressore logistico sarà la seguente:\n",
    "    1.Normalizzare i dati in ingresso  \n",
    "    2. Costruire il modulo che implementa il modello (il costruttore si preoccuperà di inizializzare i parametri)\n",
    "    3. Mettere il modello in modalità \"training\"\n",
    "    4. Calcolare l'output del modello  \n",
    "    5. Calcolare il valore della loss \n",
    "    6. Calcolare il gradiente della loss rispetto ai parametri del modello;\n",
    "    7. Aggiornare i pesi   utilizzando il gradient descent\n",
    "    8. Ripetere i passi 4-7 fino a convergenza.\n",
    "\n",
    "Implementiamo di conseguenza la procedura introducendo il monitoring delle curve tramite tensorboard e calcolo dell'accuracy ad ogni iterazione"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "Accuracy di training 0.9583333333333334\n",
      "Accuracy di test 1.0\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import SGD\n",
    "\n",
    "writer = SummaryWriter('logs/softmax_regressor')\n",
    "\n",
    "lr = 0.1\n",
    "epochs = 500\n",
    "\n",
    "## normalizzazione dei dati\n",
    "X_mean = X_training.mean(0)\n",
    "X_std = X_training.std(0)\n",
    "\n",
    "X_training_norm = (X_training-X_mean)/X_std\n",
    "X_testing_norm = (X_testing-X_mean)/X_std\n",
    "\n",
    "model = SoftMaxRegressor(4, 3)\n",
    "criterion = nn.CrossEntropyLoss()       # cross-entropy loss\n",
    "optimizer = SGD(model.parameters(), lr)  # optimizer\n",
    "\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    out = model(X_training_norm)\n",
    "    l = criterion(out, Y_training.long())\n",
    "    l.backward()\n",
    "    writer.add_scalar('loss/train', l.item(), global_step=e)\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    preds_train = out.max(1)[1]\n",
    "    writer.add_scalar('accuracy/train', accuracy_score(Y_training, preds_train), global_step=e)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        out = model(X_testing_norm)\n",
    "        l = criterion(out, Y_testing.long())\n",
    "        writer.add_scalar('loss/test', l.item(), global_step=e)\n",
    "        preds_test = out.max(1)[1]\n",
    "        writer.add_scalar('accuracy/test', accuracy_score(Y_testing, preds_test), global_step=e)\n",
    "\n",
    "\n",
    "## Calcolo accuracy di training e test\n",
    "\n",
    "preds_train = model(X_training_norm).max(1)[1]\n",
    "preds_test = model(X_testing_norm).max(1)[1]\n",
    "\n",
    "print(\"Accuracy di training\", accuracy_score(Y_training,preds_train) )\n",
    "print(\"Accuracy di test\", accuracy_score(Y_testing,preds_test) )\n"
   ]
  },
  {
   "source": [
    "## Salvataggio e caricamento di modelli\n",
    "\n",
    "Quando si allenano modelli su grandi dataset, la procedura di allenamento può essere molto lenta. Risulta dunqueconveniente poter salvare su disco i modelli in modo da poterli caricare e riutilizzare in seguito. PyTorch permette di salvare ecaricare modelli in maniera semplice. Il salvataggio viene effettuato serializzando tutti i parametri. E' possibile accedere a undizionario contenente tutti i parametri del modello utilizzando il metodo state_dict"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "odict_keys(['linear.weight', 'linear.bias'])\n"
     ]
    }
   ],
   "source": [
    "state_dict=model.state_dict()\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "source": [
    "Nel nostro caso si tratta di due soli elementi ma in generale potrebbero essercene di più. Possiamo dunque salvare il dizionario tramite torch.save:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'model.pth')"
   ]
  },
  {
   "source": [
    "per ripristinare lo stato del modello, dobbiamo prima costruire l'oggetto e poi usare il metodo load_state_dict"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "model = SoftMaxRegressor(4,3)\n",
    "model.load_state_dict(torch.load('model.pth'))"
   ]
  },
  {
   "source": [
    "## Allenamento su GPU\n",
    "\n",
    "Dato che l'allenamento di un modello su grandi quantità di dati può essere lento, risulta conveniente velocizzare i calcoli effettuando l'allenamento su GPU, qualora una GPU dovesse essere disponibile nel sistema. Vediamo alcuni semplici passi per convertire il codice di training in questo senso\n",
    "\n",
    "E' possibile verificare qualora una GPU sia disponibile nel sistema:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "source": [
    "Possiamo dunque costruire una variabile device che sia uguale a cpu se non c'è nessuna GPU disponibile e cuda altrimenti"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "source": [
    "Dobbiamo \"portare\" il modello che utilizzeremo sul device corretto:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode.to(device)"
   ]
  },
  {
   "source": [
    "La stessa operazione va effettuata su ciascun tensore con il quale lavoreremo come segue:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.8943, -1.2295, -0.4128, -0.1262],\n",
       "        [ 0.4487, -0.5708,  0.6062,  0.7799],\n",
       "        [-1.0163,  0.9660, -1.3753, -1.1617],\n",
       "        [ 0.5707, -0.5708,  0.7761,  0.3915],\n",
       "        [ 1.0591, -0.1317,  0.7195,  0.6504],\n",
       "        [-1.2605,  0.7465, -1.0356, -1.2911],\n",
       "        [-1.7488, -0.3513, -1.3187, -1.2911],\n",
       "        [-0.5280,  0.7465, -1.1488, -1.2911],\n",
       "        [-1.5047,  1.1856, -1.5451, -1.2911],\n",
       "        [-1.0163, -1.6686, -0.2430, -0.2556],\n",
       "        [-0.4059,  0.9660, -1.3753, -1.2911],\n",
       "        [ 0.4487, -1.8881,  0.4364,  0.3915],\n",
       "        [-0.7722,  2.2833, -1.2620, -1.4206],\n",
       "        [ 1.3032,  0.0878,  0.7761,  1.4270],\n",
       "        [ 1.6695,  0.3074,  1.2856,  0.7799],\n",
       "        [-1.1384,  0.0878, -1.2620, -1.4206],\n",
       "        [-0.0397, -0.5708,  0.7761,  1.5565],\n",
       "        [ 1.0591, -0.1317,  0.8327,  1.4270],\n",
       "        [ 2.2799, -0.1317,  1.3422,  1.4270],\n",
       "        [ 1.0591,  0.0878,  1.0592,  1.5565],\n",
       "        [-1.1384, -0.1317, -1.3187, -1.2911],\n",
       "        [ 0.8149, -0.1317,  0.8327,  1.0387],\n",
       "        [ 2.1578, -0.1317,  1.6253,  1.1682],\n",
       "        [ 0.4487, -0.3513,  0.3232,  0.1327],\n",
       "        [-1.1384, -1.4490, -0.2430, -0.2556],\n",
       "        [-0.2838, -0.3513, -0.0731,  0.1327],\n",
       "        [-0.2838, -0.1317,  0.4364,  0.3915],\n",
       "        [ 1.3032,  0.0878,  0.6629,  0.3915],\n",
       "        [ 0.9370, -0.3513,  0.4930,  0.1327],\n",
       "        [-0.8943,  0.9660, -1.3187, -1.1617],\n",
       "        [-0.8943,  0.7465, -1.2620, -1.2911],\n",
       "        [ 1.9136, -0.5708,  1.3422,  0.9093],\n",
       "        [-0.1618, -1.2295,  0.7195,  1.0387],\n",
       "        [ 0.8149,  0.3074,  0.7761,  1.0387],\n",
       "        [-0.8943,  1.4051, -1.2620, -1.0323],\n",
       "        [-0.4059,  2.5029, -1.3187, -1.2911],\n",
       "        [-0.8943,  0.9660, -1.3187, -1.2911],\n",
       "        [ 0.5707, -1.2295,  0.7195,  0.9093],\n",
       "        [ 0.2045, -1.8881,  0.1533, -0.2556],\n",
       "        [ 0.3266, -1.0099,  1.0592,  0.2621],\n",
       "        [ 1.0591,  0.5269,  1.1158,  1.6859],\n",
       "        [-0.1618, -0.5708,  0.4364,  0.1327],\n",
       "        [-1.0163,  1.1856, -1.3187, -1.2911],\n",
       "        [ 0.6928, -0.7904,  0.8893,  0.9093],\n",
       "        [-0.5280,  1.4051, -1.2620, -1.2911],\n",
       "        [ 2.5241,  1.6247,  1.5121,  1.0387],\n",
       "        [-0.1618,  2.9420, -1.2620, -1.0323],\n",
       "        [ 0.2045, -0.3513,  0.4364,  0.3915],\n",
       "        [-0.2838, -0.1317,  0.2099,  0.1327],\n",
       "        [-0.5280,  1.8442, -1.1488, -1.0323],\n",
       "        [-0.0397, -0.7904,  0.2099, -0.2556],\n",
       "        [-1.0163,  0.7465, -1.2620, -1.2911],\n",
       "        [ 0.4487,  0.7465,  0.9459,  1.4270],\n",
       "        [ 0.6928, -0.5708,  1.0592,  1.2976],\n",
       "        [ 0.2045, -0.1317,  0.6062,  0.7799],\n",
       "        [ 0.2045,  0.7465,  0.4364,  0.5210],\n",
       "        [-0.1618,  1.6247, -1.1488, -1.1617],\n",
       "        [-1.0163,  0.5269, -1.3187, -1.2911],\n",
       "        [ 0.0824, -0.1317,  0.7761,  0.7799],\n",
       "        [ 0.2045, -0.7904,  0.7761,  0.5210],\n",
       "        [-0.4059, -1.0099,  0.3798,  0.0032],\n",
       "        [-0.8943,  1.6247, -1.0356, -1.0323],\n",
       "        [ 1.0591,  0.0878,  0.5496,  0.3915],\n",
       "        [ 0.8149, -0.1317,  1.1724,  1.2976],\n",
       "        [ 0.0824,  0.3074,  0.6062,  0.7799],\n",
       "        [ 0.5707,  0.5269,  0.5496,  0.5210],\n",
       "        [ 0.5707, -1.2295,  0.6629,  0.3915],\n",
       "        [-1.6268, -1.6686, -1.3753, -1.1617],\n",
       "        [-0.5280,  1.8442, -1.3753, -1.0323],\n",
       "        [-1.2605, -0.1317, -1.3187, -1.1617],\n",
       "        [-0.5280, -0.1317,  0.4364,  0.3915],\n",
       "        [-0.4059, -1.2295,  0.1533,  0.1327],\n",
       "        [-0.5280,  0.7465, -1.2620, -1.0323],\n",
       "        [-0.0397, -0.7904,  0.7761,  0.9093],\n",
       "        [-0.1618, -0.1317,  0.2666,  0.0032],\n",
       "        [ 0.6928,  0.0878,  1.0026,  0.7799],\n",
       "        [-0.0397, -0.7904,  0.7761,  0.9093],\n",
       "        [-0.1618, -0.3513,  0.2666,  0.1327],\n",
       "        [-1.8709, -0.1317, -1.4885, -1.4206],\n",
       "        [ 0.5707, -1.6686,  0.3798,  0.1327],\n",
       "        [ 0.2045, -1.8881,  0.7195,  0.3915],\n",
       "        [-0.7722,  0.7465, -1.3187, -1.2911],\n",
       "        [-0.8943,  1.6247, -1.2054, -1.2911],\n",
       "        [ 1.3032,  0.0878,  0.9459,  1.1682],\n",
       "        [-1.1384, -1.2295,  0.4364,  0.6504],\n",
       "        [-1.0163, -2.3272, -0.1297, -0.2556],\n",
       "        [ 0.3266, -0.5708,  0.1533,  0.1327],\n",
       "        [-0.2838, -0.5708,  0.6629,  1.0387],\n",
       "        [-0.0397,  2.0638, -1.4319, -1.2911],\n",
       "        [-0.4059, -1.4490, -0.0165, -0.2556],\n",
       "        [ 1.7916, -0.3513,  1.4555,  0.7799],\n",
       "        [ 0.6928,  0.3074,  0.8893,  1.4270],\n",
       "        [ 1.6695, -0.1317,  1.1724,  0.5210],\n",
       "        [ 1.0591,  0.0878,  0.3798,  0.2621],\n",
       "        [-1.2605, -0.1317, -1.3187, -1.4206],\n",
       "        [-0.8943,  1.6247, -1.2620, -1.1617],\n",
       "        [-1.3826,  0.3074, -1.3753, -1.2911],\n",
       "        [-1.5047,  0.0878, -1.2620, -1.2911],\n",
       "        [ 0.5707,  0.7465,  1.0592,  1.5565],\n",
       "        [ 0.9370, -0.1317,  0.3798,  0.2621],\n",
       "        [ 0.6928, -0.5708,  1.0592,  1.1682],\n",
       "        [-1.1384,  0.0878, -1.2620, -1.2911],\n",
       "        [-1.1384,  1.1856, -1.3187, -1.4206],\n",
       "        [ 1.1812, -0.5708,  0.6062,  0.2621],\n",
       "        [ 1.4253,  0.3074,  0.5496,  0.2621],\n",
       "        [ 0.3266, -0.1317,  0.6629,  0.7799],\n",
       "        [-0.4059, -1.4490,  0.0401, -0.1262],\n",
       "        [-0.2838, -1.2295,  0.0967, -0.1262],\n",
       "        [ 1.1812, -0.1317,  1.0026,  1.1682],\n",
       "        [ 1.3032,  0.3074,  1.1158,  1.4270],\n",
       "        [ 2.2799, -1.0099,  1.7952,  1.4270],\n",
       "        [-1.0163,  0.7465, -1.2054, -1.0323],\n",
       "        [ 1.0591,  0.5269,  1.1158,  1.1682],\n",
       "        [-1.2605,  0.0878, -1.2054, -1.2911],\n",
       "        [-0.8943,  0.5269, -1.1488, -0.9028],\n",
       "        [ 1.1812,  0.3074,  1.2290,  1.4270],\n",
       "        [ 0.8149, -0.1317,  1.0026,  0.7799],\n",
       "        [-0.4059, -1.6686,  0.1533,  0.1327],\n",
       "        [-1.7488, -0.1317, -1.3753, -1.2911],\n",
       "        [-1.5047,  0.3074, -1.3187, -1.2911]])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "X_training_norm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}