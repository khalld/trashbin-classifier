{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "# custom libs\n",
    "from libs.PretrainedModels import AlexNet_cc, SqueezeNet_cc, ResNet18_cc, SqueezeNet1_cc\n",
    "from libs.utils import get_model_name, init_model, load_model\n",
    "from libs.Dataset import dst"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "random.seed(1996)\n",
    "np.random.seed(1996)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset and dataLoaders"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# parameters for dataloaders\n",
    "batch_size=32\n",
    "num_workers=2\n",
    "drop_last=True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create data loader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "dst.create_data_loader(batch_size=batch_size, num_workers=num_workers, drop_last=drop_last)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "learning_rates = {\n",
    "    'alexnet': 0.00227, \n",
    "    'squeezenet': 0.002,\n",
    "    'squeezenet1_1': 0.00282, \n",
    "    'resnet18': 0.00255\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Start to make a training of 5 epochs to see the differences between models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "num_epochs = 50\n",
    "momentum = 0.99\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_from_epoch = 0\n",
    "save_each = 10\n",
    "resume_global_step_from = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### AlexNet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "alexnet = init_model(creator=AlexNet_cc(), model_name=get_model_name(model_name='AlexNet', lr=str(learning_rates['alexnet'])), feature_extract=True, use_pretrained=True)\n",
    "alexnet.do_train(dataset=dst, num_epochs=num_epochs, lr=learning_rates['alexnet'], momentum=momentum, criterion=criterion, train_from_epoch=train_from_epoch, save_each=save_each, resume_global_step_from=resume_global_step_from)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initializing: AlexNet__lr=0.00227\n",
      "Feature extracting\n",
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "Epoch 0/49\n",
      "----------\n",
      "validation Loss: 2.5124 Acc: 0.8704\n",
      "Epoch 1/49\n",
      "----------\n",
      "validation Loss: 1.2292 Acc: 0.9284\n",
      "Epoch 2/49\n",
      "----------\n",
      "validation Loss: 1.3616 Acc: 0.9310\n",
      "Epoch 3/49\n",
      "----------\n",
      "validation Loss: 0.8292 Acc: 0.9497\n",
      "Epoch 4/49\n",
      "----------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SqueezeNet 1.0"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# to do \n",
    "squeezenet = init_model(creator=SqueezeNet_cc(), model_name=get_model_name(model_name='SqueezeNet', lr=str(learning_rates['squeezenet'])), feature_extract=True, use_pretrained=True)\n",
    "squeezenet.do_train(dataset=dst, num_epochs=num_epochs, lr=learning_rates['squeezenet'], momentum=momentum, criterion=criterion, train_from_epoch=train_from_epoch, save_each=save_each, resume_global_step_from=resume_global_step_from )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initializing: SqueezeNet__lr=0.002\n",
      "Feature extracting\n",
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "Epoch 0/49\n",
      "----------\n",
      "validation Loss: 0.3049 Acc: 0.8925\n",
      "Epoch 1/49\n",
      "----------\n",
      "validation Loss: 0.2364 Acc: 0.9146\n",
      "Epoch 2/49\n",
      "----------\n",
      "validation Loss: 0.2167 Acc: 0.9230\n",
      "Epoch 3/49\n",
      "----------\n",
      "validation Loss: 0.2004 Acc: 0.9242\n",
      "Epoch 4/49\n",
      "----------\n",
      "validation Loss: 0.1895 Acc: 0.9333\n",
      "Epoch 5/49\n",
      "----------\n",
      "validation Loss: 0.1715 Acc: 0.9356\n",
      "Epoch 6/49\n",
      "----------\n",
      "validation Loss: 0.1639 Acc: 0.9432\n",
      "Epoch 7/49\n",
      "----------\n",
      "validation Loss: 0.1671 Acc: 0.9432\n",
      "Epoch 8/49\n",
      "----------\n",
      "validation Loss: 0.1722 Acc: 0.9333\n",
      "Epoch 9/49\n",
      "----------\n",
      "validation Loss: 0.1421 Acc: 0.9531\n",
      "Epoch 10/49\n",
      "----------\n",
      "validation Loss: 0.1641 Acc: 0.9455\n",
      "Epoch 11/49\n",
      "----------\n",
      "validation Loss: 0.1306 Acc: 0.9569\n",
      "Epoch 12/49\n",
      "----------\n",
      "validation Loss: 0.1305 Acc: 0.9546\n",
      "Epoch 13/49\n",
      "----------\n",
      "validation Loss: 0.1219 Acc: 0.9596\n",
      "Epoch 14/49\n",
      "----------\n",
      "validation Loss: 0.1652 Acc: 0.9428\n",
      "Epoch 15/49\n",
      "----------\n",
      "validation Loss: 0.1258 Acc: 0.9566\n",
      "Epoch 16/49\n",
      "----------\n",
      "validation Loss: 0.1233 Acc: 0.9512\n",
      "Epoch 17/49\n",
      "----------\n",
      "validation Loss: 0.1071 Acc: 0.9653\n",
      "Epoch 18/49\n",
      "----------\n",
      "validation Loss: 0.1405 Acc: 0.9493\n",
      "Epoch 19/49\n",
      "----------\n",
      "validation Loss: 0.1265 Acc: 0.9474\n",
      "Epoch 20/49\n",
      "----------\n",
      "validation Loss: 0.1230 Acc: 0.9569\n",
      "Epoch 21/49\n",
      "----------\n",
      "validation Loss: 0.1128 Acc: 0.9592\n",
      "Epoch 22/49\n",
      "----------\n",
      "validation Loss: 0.0822 Acc: 0.9699\n",
      "Epoch 23/49\n",
      "----------\n",
      "validation Loss: 0.0995 Acc: 0.9649\n",
      "Epoch 24/49\n",
      "----------\n",
      "validation Loss: 0.1023 Acc: 0.9634\n",
      "Epoch 25/49\n",
      "----------\n",
      "validation Loss: 0.1154 Acc: 0.9600\n",
      "Epoch 26/49\n",
      "----------\n",
      "validation Loss: 0.1040 Acc: 0.9638\n",
      "Epoch 27/49\n",
      "----------\n",
      "validation Loss: 0.1083 Acc: 0.9604\n",
      "Epoch 28/49\n",
      "----------\n",
      "validation Loss: 0.0988 Acc: 0.9695\n",
      "Epoch 29/49\n",
      "----------\n",
      "validation Loss: 0.1123 Acc: 0.9623\n",
      "Epoch 30/49\n",
      "----------\n",
      "validation Loss: 0.0958 Acc: 0.9668\n",
      "Epoch 31/49\n",
      "----------\n",
      "validation Loss: 0.1008 Acc: 0.9630\n",
      "Epoch 32/49\n",
      "----------\n",
      "validation Loss: 0.0980 Acc: 0.9691\n",
      "Epoch 33/49\n",
      "----------\n",
      "validation Loss: 0.0998 Acc: 0.9668\n",
      "Epoch 34/49\n",
      "----------\n",
      "validation Loss: 0.0951 Acc: 0.9653\n",
      "Epoch 35/49\n",
      "----------\n",
      "validation Loss: 0.0893 Acc: 0.9684\n",
      "Epoch 36/49\n",
      "----------\n",
      "validation Loss: 0.1013 Acc: 0.9680\n",
      "Epoch 37/49\n",
      "----------\n",
      "validation Loss: 0.0981 Acc: 0.9665\n",
      "Epoch 38/49\n",
      "----------\n",
      "validation Loss: 0.0944 Acc: 0.9676\n",
      "Epoch 39/49\n",
      "----------\n",
      "validation Loss: 0.1114 Acc: 0.9566\n",
      "Epoch 40/49\n",
      "----------\n",
      "validation Loss: 0.0976 Acc: 0.9638\n",
      "Epoch 41/49\n",
      "----------\n",
      "validation Loss: 0.1145 Acc: 0.9607\n",
      "Epoch 42/49\n",
      "----------\n",
      "validation Loss: 0.0922 Acc: 0.9699\n",
      "Epoch 43/49\n",
      "----------\n",
      "validation Loss: 0.0952 Acc: 0.9665\n",
      "Epoch 44/49\n",
      "----------\n",
      "validation Loss: 0.0903 Acc: 0.9668\n",
      "Epoch 45/49\n",
      "----------\n",
      "validation Loss: 0.1103 Acc: 0.9588\n",
      "Epoch 46/49\n",
      "----------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SqueezeNet 1.1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "squeezenet1_1 = init_model(creator=SqueezeNet1_cc(), model_name=get_model_name(model_name='SqueezeNet1_1', lr=str(learning_rates['squeezenet1_1'])), feature_extract=True, use_pretrained=True)\n",
    "squeezenet1_1.do_train(dataset=dst, num_epochs=num_epochs, lr=learning_rates['squeezenet1_1'], momentum=momentum, criterion=criterion, train_from_epoch=train_from_epoch, save_each=save_each, resume_global_step_from=resume_global_step_from )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ResNet-18"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "resnet18 = init_model(creator=ResNet18_cc(), model_name=get_model_name(model_name='ResNet18', lr=str(learning_rates['resnet18'])), feature_extract=True, use_pretrained=True)\n",
    "resnet18.do_train(dataset=dst, num_epochs=num_epochs, lr=learning_rates['resnet18'], momentum=momentum, criterion=criterion, train_from_epoch=train_from_epoch, save_each=save_each, resume_global_step_from=resume_global_step_from )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initializing: ResNet18__lr=0.00255\n",
      "Feature extracting\n",
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "Epoch 0/49\n",
      "----------\n",
      "validation Loss: 0.2604 Acc: 0.9272\n",
      "Epoch 1/49\n",
      "----------\n",
      "validation Loss: 0.3098 Acc: 0.9333\n",
      "Epoch 2/49\n",
      "----------\n",
      "validation Loss: 0.2485 Acc: 0.9402\n",
      "Epoch 3/49\n",
      "----------\n",
      "validation Loss: 0.2296 Acc: 0.9501\n",
      "Epoch 4/49\n",
      "----------\n",
      "validation Loss: 1.0046 Acc: 0.8537\n",
      "Epoch 5/49\n",
      "----------\n",
      "validation Loss: 0.3299 Acc: 0.9375\n",
      "Epoch 6/49\n",
      "----------\n",
      "validation Loss: 0.7834 Acc: 0.8880\n",
      "Epoch 7/49\n",
      "----------\n",
      "validation Loss: 0.2959 Acc: 0.9417\n",
      "Epoch 8/49\n",
      "----------\n",
      "validation Loss: 0.3085 Acc: 0.9451\n",
      "Epoch 9/49\n",
      "----------\n",
      "validation Loss: 0.4263 Acc: 0.9211\n",
      "Epoch 10/49\n",
      "----------\n",
      "validation Loss: 0.1576 Acc: 0.9550\n",
      "Epoch 11/49\n",
      "----------\n",
      "validation Loss: 0.3311 Acc: 0.9314\n",
      "Epoch 12/49\n",
      "----------\n",
      "validation Loss: 0.2207 Acc: 0.9527\n",
      "Epoch 13/49\n",
      "----------\n",
      "validation Loss: 0.3050 Acc: 0.9356\n",
      "Epoch 14/49\n",
      "----------\n",
      "validation Loss: 0.2518 Acc: 0.9554\n",
      "Epoch 15/49\n",
      "----------\n",
      "validation Loss: 0.2434 Acc: 0.9524\n",
      "Epoch 16/49\n",
      "----------\n",
      "validation Loss: 0.4658 Acc: 0.9299\n",
      "Epoch 17/49\n",
      "----------\n",
      "validation Loss: 0.2922 Acc: 0.9394\n",
      "Epoch 18/49\n",
      "----------\n",
      "validation Loss: 0.2423 Acc: 0.9478\n",
      "Epoch 19/49\n",
      "----------\n",
      "validation Loss: 0.1972 Acc: 0.9539\n",
      "Epoch 20/49\n",
      "----------\n",
      "validation Loss: 0.2794 Acc: 0.9413\n",
      "Epoch 21/49\n",
      "----------\n",
      "validation Loss: 0.4919 Acc: 0.9135\n",
      "Epoch 22/49\n",
      "----------\n",
      "validation Loss: 0.3042 Acc: 0.9303\n",
      "Epoch 23/49\n",
      "----------\n",
      "validation Loss: 0.1710 Acc: 0.9577\n",
      "Epoch 24/49\n",
      "----------\n",
      "validation Loss: 0.2261 Acc: 0.9543\n",
      "Epoch 25/49\n",
      "----------\n",
      "validation Loss: 0.3159 Acc: 0.9425\n",
      "Epoch 26/49\n",
      "----------\n",
      "validation Loss: 0.2777 Acc: 0.9402\n",
      "Epoch 27/49\n",
      "----------\n",
      "validation Loss: 0.2863 Acc: 0.9356\n",
      "Epoch 28/49\n",
      "----------\n",
      "validation Loss: 0.6047 Acc: 0.8921\n",
      "Epoch 29/49\n",
      "----------\n",
      "validation Loss: 0.2925 Acc: 0.9386\n",
      "Epoch 30/49\n",
      "----------\n",
      "validation Loss: 0.2301 Acc: 0.9478\n",
      "Epoch 31/49\n",
      "----------\n",
      "validation Loss: 0.9426 Acc: 0.8434\n",
      "Epoch 32/49\n",
      "----------\n",
      "validation Loss: 0.3143 Acc: 0.9470\n",
      "Epoch 33/49\n",
      "----------\n",
      "validation Loss: 0.2403 Acc: 0.9489\n",
      "Epoch 34/49\n",
      "----------\n",
      "validation Loss: 0.2134 Acc: 0.9585\n",
      "Epoch 35/49\n",
      "----------\n",
      "validation Loss: 0.2504 Acc: 0.9516\n",
      "Epoch 36/49\n",
      "----------\n",
      "validation Loss: 0.2576 Acc: 0.9478\n",
      "Epoch 37/49\n",
      "----------\n",
      "validation Loss: 0.3676 Acc: 0.9284\n",
      "Epoch 38/49\n",
      "----------\n",
      "validation Loss: 0.2223 Acc: 0.9585\n",
      "Epoch 39/49\n",
      "----------\n",
      "validation Loss: 0.2823 Acc: 0.9466\n",
      "Epoch 40/49\n",
      "----------\n",
      "validation Loss: 0.2277 Acc: 0.9546\n",
      "Epoch 41/49\n",
      "----------\n",
      "validation Loss: 0.6205 Acc: 0.9055\n",
      "Epoch 42/49\n",
      "----------\n",
      "validation Loss: 0.7218 Acc: 0.8952\n",
      "Epoch 43/49\n",
      "----------\n",
      "validation Loss: 0.5639 Acc: 0.9245\n",
      "Epoch 44/49\n",
      "----------\n",
      "validation Loss: 0.2856 Acc: 0.9497\n",
      "Epoch 45/49\n",
      "----------\n",
      "validation Loss: 0.3675 Acc: 0.9470\n",
      "Epoch 46/49\n",
      "----------\n",
      "validation Loss: 0.4183 Acc: 0.9314\n",
      "Epoch 47/49\n",
      "----------\n",
      "validation Loss: 0.4203 Acc: 0.9322\n",
      "Epoch 48/49\n",
      "----------\n",
      "validation Loss: 0.3204 Acc: 0.9463\n",
      "Epoch 49/49\n",
      "----------\n",
      "validation Loss: 0.7499 Acc: 0.8937\n",
      "Training complete in 450m 5s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test accuracy -- todo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### il migliore dopo 50 epoche lo provi con batch size diverso, fai in un nuovo notebook i calcoli con batch a 64 e 128 e vedi se ci sono miglioramenti\n",
    "### poi continua quello salvato con altre ulteriori 100 epoche"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "trained_models = {\n",
    "    'alexnet': 'models/AlexNet__lr=0.00227-50.pth', \n",
    "    'squeezenet': 'models/SqueezeNet__lr=0.002-50.pth',\n",
    "    'squeezenet1_1': 'models/SqueezeNet1_1__lr=0.00282/SqueezeNet1_1__lr=0.00282-50.pth', \n",
    "    'resnet18': 'models/ResNet18__lr=0.00255-50.pth'\n",
    "}\n",
    "\n",
    "concreteCreators = {\n",
    "    'alexnet': AlexNet_cc(),\n",
    "    'squeezenet': SqueezeNet_cc(),\n",
    "    'squeezenet1_1': SqueezeNet1_cc(),\n",
    "    'resnet18': ResNet18_cc()\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "for name in trained_models:\n",
    "    model = load_model(creator=concreteCreators[name], model_name=get_model_name(model_name=name, lr=str(learning_rates[name])), num_classes=3, model_path=trained_models[name])\n",
    "    model.test_accuracy(dataset=dst)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initializing: alexnet__lr=0.00227\n",
      "Loading model using load_state_dict..\n",
      "Model loaded sucessfully!\n",
      "Loaded model from file successfully\n",
      "Accuracy of alexnet__lr=0.00227: 83.97%\n",
      "Initializing: squeezenet__lr=0.002\n",
      "Loading model using load_state_dict..\n",
      "Model loaded sucessfully!\n",
      "Loaded model from file successfully\n",
      "Accuracy of squeezenet__lr=0.002: 86.53%\n",
      "Initializing: squeezenet1_1__lr=0.00282\n",
      "Loading model using load_state_dict..\n",
      "Model loaded sucessfully!\n",
      "Loaded model from file successfully\n",
      "Accuracy of squeezenet1_1__lr=0.00282: 86.20%\n",
      "Initializing: resnet18__lr=0.00255\n",
      "Loading model using load_state_dict..\n",
      "Model loaded sucessfully!\n",
      "Loaded model from file successfully\n",
      "Accuracy of resnet18__lr=0.00255: 79.12%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Continue training squeezenet (best model)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "num_epochs = 20\n",
    "momentum = 0.99\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_from_epoch = 50\n",
    "save_each = 5\n",
    "resume_global_step_from = 458176 # need for tensorboard"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "best_model = load_model(creator=concreteCreators['squeezenet'], model_name=get_model_name(model_name='SqueezeNet', lr=str(learning_rates['squeezenet'])), num_classes=3, model_path='models/SqueezeNet__lr=0.002-50.pth' )\n",
    "best_model.do_train(dataset=dst, num_epochs=num_epochs, lr=learning_rates['squeezenet'], momentum=momentum, criterion=criterion, train_from_epoch=train_from_epoch, save_each=save_each, resume_global_step_from=resume_global_step_from)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initializing: SqueezeNet__lr=0.002\n",
      "Loading model using load_state_dict..\n",
      "Model loaded sucessfully!\n",
      "Loaded model from file successfully\n",
      "Feature extracting\n",
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "Epoch 0/19\n",
      "----------\n",
      "validation Loss: 0.1028 Acc: 0.9619\n",
      "Epoch 1/19\n",
      "----------\n",
      "validation Loss: 0.0961 Acc: 0.9642\n",
      "Epoch 2/19\n",
      "----------\n",
      "validation Loss: 0.0814 Acc: 0.9703\n",
      "Epoch 3/19\n",
      "----------\n",
      "validation Loss: 0.0878 Acc: 0.9703\n",
      "Epoch 4/19\n",
      "----------\n",
      "validation Loss: 0.1102 Acc: 0.9634\n",
      "Epoch 5/19\n",
      "----------\n",
      "validation Loss: 0.0816 Acc: 0.9684\n",
      "Epoch 6/19\n",
      "----------\n",
      "validation Loss: 0.0871 Acc: 0.9684\n",
      "Epoch 7/19\n",
      "----------\n",
      "validation Loss: 0.0807 Acc: 0.9726\n",
      "Epoch 8/19\n",
      "----------\n",
      "validation Loss: 0.0864 Acc: 0.9718\n",
      "Epoch 9/19\n",
      "----------\n",
      "validation Loss: 0.1055 Acc: 0.9665\n",
      "Epoch 10/19\n",
      "----------\n",
      "validation Loss: 0.0924 Acc: 0.9722\n",
      "Epoch 11/19\n",
      "----------\n",
      "validation Loss: 0.0924 Acc: 0.9657\n",
      "Epoch 12/19\n",
      "----------\n",
      "validation Loss: 0.0994 Acc: 0.9676\n",
      "Epoch 13/19\n",
      "----------\n",
      "validation Loss: 0.0943 Acc: 0.9653\n",
      "Epoch 14/19\n",
      "----------\n",
      "validation Loss: 0.1321 Acc: 0.9554\n",
      "Epoch 15/19\n",
      "----------\n",
      "validation Loss: 0.0994 Acc: 0.9638\n",
      "Epoch 16/19\n",
      "----------\n",
      "validation Loss: 0.0864 Acc: 0.9684\n",
      "Epoch 17/19\n",
      "----------\n",
      "validation Loss: 0.0873 Acc: 0.9661\n",
      "Epoch 18/19\n",
      "----------\n",
      "validation Loss: 0.0956 Acc: 0.9691\n",
      "Epoch 19/19\n",
      "----------\n",
      "validation Loss: 0.1001 Acc: 0.9634\n",
      "Training complete in 129m 3s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SqueezeNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (3): Fire(\n",
       "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Fire(\n",
       "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Fire(\n",
       "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (7): Fire(\n",
       "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Fire(\n",
       "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Fire(\n",
       "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Fire(\n",
       "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (12): Fire(\n",
       "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Conv2d(512, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "model = load_model(creator=concreteCreators['squeezenet'], model_name=get_model_name(model_name='SqueezeNet', lr=str(learning_rates['squeezenet'])), num_classes=3, model_path='models/SqueezeNet__lr=0.002-70.pth')\n",
    "model.test_accuracy(dataset=dst)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initializing: SqueezeNet__lr=0.002\n",
      "Loading model using load_state_dict..\n",
      "Model loaded sucessfully!\n",
      "Loaded model from file successfully\n",
      "Accuracy of SqueezeNet__lr=0.002: 87.12%\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}