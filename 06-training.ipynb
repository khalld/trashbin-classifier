{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "# custom libs\n",
    "from libs.PretrainedModels import AlexNet_cc, SqueezeNet_cc, ResNet18_cc, SqueezeNet1_cc\n",
    "from libs.utils import get_model_name, init_model\n",
    "from libs.Dataset import dst"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "random.seed(1996)\n",
    "np.random.seed(1996)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset and dataLoaders"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# parameters for dataloaders\n",
    "batch_size=32\n",
    "num_workers=2\n",
    "drop_last=True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create data loader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "dst.create_data_loader(batch_size=batch_size, num_workers=num_workers, drop_last=drop_last)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# da ritrainare tutti per 50 epoche\n",
    "\n",
    "learning_rates = {\n",
    "    'alexnet': 0.00227, \n",
    "    'squeezenet': 0.002,\n",
    "    'squeezenet1_1': 0.00282, \n",
    "    'resnet18': 0.00255,\n",
    "    # 'inceptionv3': '' need to be tested\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Start to make a training of 5 epochs to see the differences between models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "num_epochs = 50\n",
    "momentum = 0.99\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_from_epoch = 0\n",
    "save_each = 5\n",
    "resume_global_step_from = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# to do \n",
    "\n",
    "alexnet = init_model(creator=AlexNet_cc(), model_name=get_model_name(model_name='AlexNet', lr=str(learning_rates['alexnet'])), feature_extract=True, use_pretrained=True)\n",
    "alexnet.do_train(dataset=dst, num_epochs=num_epochs, lr=learning_rates['alexnet'], momentum=momentum, criterion=criterion, train_from_epoch=train_from_epoch, save_each=save_each, resume_global_step_from=resume_global_step_from)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# to do \n",
    "\n",
    "squeezenet = init_model(creator=SqueezeNet_cc(), model_name=get_model_name(model_name='SqueezeNet', lr=str(learning_rates['squeezenet'])), feature_extract=True, use_pretrained=True)\n",
    "squeezenet.do_train(dataset=dst, num_epochs=num_epochs, lr=learning_rates['squeezenet'], momentum=momentum, criterion=criterion, train_from_epoch=train_from_epoch, save_each=save_each, resume_global_step_from=resume_global_step_from )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# training per 50 epoche fatto\n",
    "squeezenet1_1 = init_model(creator=SqueezeNet1_cc(), model_name=get_model_name(model_name='SqueezeNet1_1', lr=str(learning_rates['squeezenet1_1'])), feature_extract=True, use_pretrained=True)\n",
    "squeezenet1_1.do_train(dataset=dst, num_epochs=num_epochs, lr=learning_rates['squeezenet1_1'], momentum=momentum, criterion=criterion, train_from_epoch=train_from_epoch, save_each=save_each, resume_global_step_from=resume_global_step_from )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#too many files opened, blocked at iteration 39\n",
    "\n",
    "resnet18 = init_model(creator=ResNet18_cc(), model_name=get_model_name(model_name='ResNet18', lr=str(learning_rates['resnet18'])), feature_extract=True, use_pretrained=True)\n",
    "resnet18.do_train(dataset=dst, num_epochs=num_epochs, lr=learning_rates['resnet18'], momentum=momentum, criterion=criterion, train_from_epoch=train_from_epoch, save_each=save_each, resume_global_step_from=resume_global_step_from )"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}